# Optimizing Tensorflow models for inference

Gradient supports deployment of models compatible with industry standards. There are a variety of optimizations you can perform on neural networks to reduce the size & latency for inference.  As we use TFServing for tensorflow models, we are able to support deployment of these optimized graphs.  

